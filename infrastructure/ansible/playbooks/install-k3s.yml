---
# Установка k3s на master ноды
- name: Install k3s on master nodes
  hosts: masters
  become: yes
  gather_facts: yes

  vars:
    k3s_install_url: https://get.k3s.io

  tasks:
    - name: Check if k3s is already installed
      stat:
        path: /usr/local/bin/k3s
      register: k3s_installed

    - name: Create k3s config directory
      file:
        path: /etc/rancher/k3s
        state: directory
        mode: '0755'

    - name: Create k3s server config
      copy:
        dest: /etc/rancher/k3s/config.yaml
        content: |
          write-kubeconfig-mode: "0644"
          
          tls-san:
            - "{{ ansible_host }}"
            - "{{ internal_ip }}"
            - "{{ ansible_hostname }}"
          
          disable:
            - traefik
          
          cluster-init: true
          
          kubelet-arg:
            - "eviction-hard=memory.available<100Mi,nodefs.available<1Gi,imagefs.available<1Gi"
            - "eviction-soft=memory.available<200Mi,nodefs.available<2Gi,imagefs.available<2Gi"
            - "eviction-soft-grace-period=memory.available=1m,nodefs.available=1m,imagefs.available=1m"
          
          kube-controller-manager-arg:
            - "node-monitor-grace-period=30s"
            - "node-monitor-period=5s"
          
          kube-apiserver-arg:
            - "default-not-ready-toleration-seconds=30"
            - "default-unreachable-toleration-seconds=30"
          
          etcd-expose-metrics: true

    - name: Download and install k3s
      shell: |
        curl -sfL {{ k3s_install_url }} | \
          INSTALL_K3S_VERSION="{{ k3s_version }}" \
          sh -s - server --cluster-init
      when: not k3s_installed.stat.exists

    - name: Wait for k3s to be ready
      wait_for:
        port: 6443
        host: "{{ internal_ip }}"
        delay: 10
        timeout: 300

    - name: Wait for node to be ready
      shell: |
        /usr/local/bin/k3s kubectl wait --for=condition=Ready node/{{ ansible_hostname }} --timeout=300s
      register: wait_node_ready
      retries: 3
      delay: 10
      until: wait_node_ready.rc == 0

    - name: Label master nodes after k3s is ready
      shell: |
        /usr/local/bin/k3s kubectl label nodes {{ ansible_hostname }} node-role.kubernetes.io/master=true --overwrite
        /usr/local/bin/k3s kubectl label nodes {{ ansible_hostname }} node-role.kubernetes.io/control-plane=true --overwrite
      register: label_result
      retries: 5
      delay: 10
      until: label_result.rc == 0

    - name: Get node token
      slurp:
        src: /var/lib/rancher/k3s/server/node-token
      register: node_token

    - name: Set token fact
      set_fact:
        k3s_token: "{{ node_token.content | b64decode | trim }}"

    - name: Get master IP
      set_fact:
        master_ip: "{{ internal_ip }}"

    - name: Create .kube directory for ubuntu user
      file:
        path: /home/ubuntu/.kube
        state: directory
        owner: ubuntu
        group: ubuntu
        mode: '0755'

    - name: Copy kubeconfig to ubuntu user
      copy:
        src: /etc/rancher/k3s/k3s.yaml
        dest: /home/ubuntu/.kube/config
        remote_src: yes
        owner: ubuntu
        group: ubuntu
        mode: '0600'

    - name: Update kubeconfig with correct server URL
      replace:
        path: /home/ubuntu/.kube/config
        regexp: 'https://127.0.0.1:6443'
        replace: 'https://{{ internal_ip }}:6443'

    - name: Install kubectl completion for ubuntu user
      shell: |
        echo 'source <(kubectl completion bash)' >> /home/ubuntu/.bashrc
        echo 'alias k=kubectl' >> /home/ubuntu/.bashrc
        echo 'complete -o default -F __start_kubectl k' >> /home/ubuntu/.bashrc
      become_user: ubuntu

    - name: Install additional tools
      shell: |
        # Install kubectl
        if ! command -v kubectl &> /dev/null; then
          curl -LO "https://dl.k8s.io/release/v1.28.0/bin/linux/amd64/kubectl"
          chmod +x kubectl
          mv kubectl /usr/local/bin/
        fi
        
        # Install Helm
        if ! command -v helm &> /dev/null; then
          curl https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 | bash
        fi

# Установка k3s на worker ноды
- name: Install k3s on worker nodes
  hosts: workers
  become: yes
  gather_facts: yes

  vars:
    k3s_install_url: https://get.k3s.io
    master_host: "{{ groups['masters'][0] }}"

  tasks:
    - name: Get master facts
      set_fact:
        k3s_token: "{{ hostvars[master_host]['k3s_token'] }}"
        master_ip: "{{ hostvars[master_host]['master_ip'] }}"

    - name: Check if k3s is already installed
      stat:
        path: /usr/local/bin/k3s
      register: k3s_installed

    - name: Create k3s config directory
      file:
        path: /etc/rancher/k3s
        state: directory
        mode: '0755'

    - name: Create k3s agent config
      copy:
        dest: /etc/rancher/k3s/config.yaml
        content: |
          kubelet-arg:
            - "eviction-hard=memory.available<100Mi,nodefs.available<1Gi,imagefs.available<1Gi"
            - "eviction-soft=memory.available<200Mi,nodefs.available<2Gi,imagefs.available<2Gi"
            - "eviction-soft-grace-period=memory.available=1m,nodefs.available=1m,imagefs.available=1m"

    - name: Install k3s agent
      shell: |
        curl -sfL {{ k3s_install_url }} | \
          K3S_URL="https://{{ master_ip }}:6443" \
          K3S_TOKEN="{{ k3s_token }}" \
          INSTALL_K3S_VERSION="{{ k3s_version }}" \
          sh -s - agent
      when: not k3s_installed.stat.exists

    - name: Wait for agent to be ready
      pause:
        seconds: 30

# Настройка кластера после установки
- name: Configure cluster
  hosts: masters[0]
  become: yes
  gather_facts: no

  tasks:
    - name: Wait for all nodes to be ready
      shell: |
        ready_count=$(/usr/local/bin/k3s kubectl get nodes --no-headers | grep -c " Ready ")
        total_count={{ groups['all'] | length }}
        [ "$ready_count" -eq "$total_count" ]
      register: nodes_ready
      until: nodes_ready.rc == 0
      retries: 30
      delay: 10

    - name: Label nodes
      shell: |
        # Label master nodes
        {% for host in groups['masters'] %}
        /usr/local/bin/k3s kubectl label nodes {{ hostvars[host]['ansible_hostname'] }} node-role.kubernetes.io/master=true --overwrite
        /usr/local/bin/k3s kubectl label nodes {{ hostvars[host]['ansible_hostname'] }} node-role.kubernetes.io/control-plane=true --overwrite
        {% endfor %}
        
        # Label worker nodes
        {% for host in groups['workers'] %}
        /usr/local/bin/k3s kubectl label nodes {{ hostvars[host]['ansible_hostname'] }} node-role.kubernetes.io/worker=true --overwrite
        /usr/local/bin/k3s kubectl label nodes {{ hostvars[host]['ansible_hostname'] }} workload=airflow --overwrite
        {% endfor %}
      ignore_errors: yes

    - name: Create namespaces
      shell: |
        /usr/local/bin/k3s kubectl create namespace {{ item }} --dry-run=client -o yaml | \
        /usr/local/bin/k3s kubectl apply -f -
      loop:
        - airflow
        - monitoring
        - argocd
        - ingress-nginx

    - name: Install metrics-server patch
      shell: |
        /usr/local/bin/k3s kubectl patch deployment metrics-server \
          -n kube-system \
          --type='json' \
          -p='[{"op": "add", "path": "/spec/template/spec/containers/0/args/-", "value": "--kubelet-insecure-tls"}]'
      ignore_errors: yes

    - name: Install Prometheus CRDs
      shell: |
        kubectl apply -f https://raw.githubusercontent.com/prometheus-operator/prometheus-operator/v0.71.2/example/prometheus-operator-crd/monitoring.coreos.com_servicemonitors.yaml
        kubectl apply -f https://raw.githubusercontent.com/prometheus-operator/prometheus-operator/v0.71.2/example/prometheus-operator-crd/monitoring.coreos.com_prometheuses.yaml
        kubectl apply -f https://raw.githubusercontent.com/prometheus-operator/prometheus-operator/v0.71.2/example/prometheus-operator-crd/monitoring.coreos.com_prometheusrules.yaml
        kubectl apply -f https://raw.githubusercontent.com/prometheus-operator/prometheus-operator/v0.71.2/example/prometheus-operator-crd/monitoring.coreos.com_alertmanagers.yaml
        kubectl apply -f https://raw.githubusercontent.com/prometheus-operator/prometheus-operator/v0.71.2/example/prometheus-operator-crd/monitoring.coreos.com_podmonitors.yaml
        kubectl apply -f https://raw.githubusercontent.com/prometheus-operator/prometheus-operator/v0.71.2/example/prometheus-operator-crd/monitoring.coreos.com_thanosrulers.yaml
      environment:
        KUBECONFIG: /etc/rancher/k3s/k3s.yaml

    - name: Setup NFS server
      block:
        - name: Wait for automatic updates to finish
          shell: |
            while fuser /var/lib/dpkg/lock-frontend >/dev/null 2>&1 || fuser /var/lib/dpkg/lock >/dev/null 2>&1 || fuser /var/lib/apt/lists/lock >/dev/null 2>&1; do
              echo "Waiting for dpkg lock to be released..."
              sleep 5
            done
          changed_when: false

        - name: Stop and disable unattended-upgrades
          systemd:
            name: unattended-upgrades
            state: stopped
            enabled: no
          failed_when: false

        - name: Install NFS server packages
          apt:
            name: nfs-kernel-server
            state: present
            update_cache: yes
          retries: 3
          delay: 10

        - name: Create NFS directory
          file:
            path: /srv/nfs/k8s
            state: directory
            mode: '0777'
            owner: nobody
            group: nogroup

        - name: Configure NFS exports
          lineinfile:
            path: /etc/exports
            line: "/srv/nfs/k8s *(rw,sync,no_subtree_check,no_root_squash)"
            create: yes

        - name: Export NFS shares
          command: exportfs -a
          changed_when: false

        - name: Ensure NFS server is running
          systemd:
            name: nfs-kernel-server
            state: started
            enabled: yes

        - name: Verify NFS is working
          command: showmount -e localhost
          register: nfs_exports
          changed_when: false

        - name: Show NFS exports
          debug:
            var: nfs_exports.stdout_lines

    - name: Add Helm repository for NFS provisioner
      shell: |
        helm repo add nfs-subdir-external-provisioner https://kubernetes-sigs.github.io/nfs-subdir-external-provisioner/
        helm repo update
      environment:
        KUBECONFIG: /etc/rancher/k3s/k3s.yaml

    - name: Setup local-path as default storage class
      shell: |
        /usr/local/bin/k3s kubectl patch storageclass local-path -p '{"metadata": {"annotations":{"storageclass.kubernetes.io/is-default-class":"true"}}}'
        /usr/local/bin/k3s kubectl get storageclass
      environment:
        KUBECONFIG: /etc/rancher/k3s/k3s.yaml

    - name: Install cert-manager
      shell: |
        /usr/local/bin/k3s kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.13.0/cert-manager.yaml
        /usr/local/bin/k3s kubectl wait --for=condition=available --timeout=300s deployment/cert-manager -n cert-manager
        /usr/local/bin/k3s kubectl wait --for=condition=available --timeout=300s deployment/cert-manager-webhook -n cert-manager
        /usr/local/bin/k3s kubectl wait --for=condition=available --timeout=300s deployment/cert-manager-cainjector -n cert-manager

    - name: Create ClusterIssuer for Let's Encrypt
      shell: |
        cat <<EOF | /usr/local/bin/k3s kubectl apply -f -
        apiVersion: cert-manager.io/v1
        kind: ClusterIssuer
        metadata:
          name: letsencrypt-prod
        spec:
          acme:
            server: https://acme-v02.api.letsencrypt.org/directory
            email: admin@example.com
            privateKeySecretRef:
              name: letsencrypt-prod
            solvers:
            - http01:
                ingress:
                  class: nginx
        ---
        apiVersion: cert-manager.io/v1
        kind: ClusterIssuer
        metadata:
          name: letsencrypt-staging
        spec:
          acme:
            server: https://acme-staging-v02.api.letsencrypt.org/directory
            email: admin@example.com
            privateKeySecretRef:
              name: letsencrypt-staging
            solvers:
            - http01:
                ingress:
                  class: nginx
        EOF

    - name: Display cluster information
      shell: |
        echo "==================================="
        echo "Kubernetes Cluster Information"
        echo "==================================="
        echo ""
        echo "Nodes:"
        /usr/local/bin/k3s kubectl get nodes -o wide
        echo ""
        echo "Namespaces:"
        /usr/local/bin/k3s kubectl get namespaces
        echo ""
        echo "Storage Classes:"
        /usr/local/bin/k3s kubectl get storageclass
        echo ""
        echo "Pods in kube-system:"
        /usr/local/bin/k3s kubectl get pods -n kube-system
        echo ""
        echo "==================================="
        echo "Cluster is ready!"
        echo "==================================="
      register: cluster_info

    - name: Show cluster info
      debug:
        msg: "{{ cluster_info.stdout_lines }}"