# kubernetes/argocd/apps/loki-stack.yaml
# ArgoCD Application для Loki Stack с S3 storage

apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: loki-stack
  namespace: argocd
  finalizers:
    - resources-finalizer.argocd.argoproj.io
spec:
  project: production

  source:
    repoURL: https://grafana.github.io/helm-charts
    targetRevision: 2.9.11
    chart: loki-stack
    helm:
      releaseName: loki-stack
      values: |
        # Loki configuration
        loki:
          enabled: true
          
          # Используем Deployment вместо StatefulSet
          deploymentMode: SingleBinary
          
          # Отключаем persistence так как используем S3
          persistence:
            enabled: false
            
          # Переключаем на Deployment
          statefulSet:
            enabled: false
          
          # Resources
          resources:
            requests:
              cpu: 100m
              memory: 256Mi
            limits:
              cpu: 500m
              memory: 1Gi
              
          # Config
          config:
            auth_enabled: false
            
            ingester:
              chunk_idle_period: 3m
              chunk_block_size: 262144
              chunk_retain_period: 1m
              max_transfer_retries: 0
              lifecycler:
                ring:
                  kvstore:
                    store: inmemory
                  replication_factor: 1
                  
            limits_config:
              enforce_metric_name: false
              reject_old_samples: true
              reject_old_samples_max_age: 168h
              max_entries_limit_per_query: 5000
              ingestion_rate_mb: 10
              ingestion_burst_size_mb: 20
              
            schema_config:
              configs:
              - from: 2020-10-24
                store: boltdb-shipper
                object_store: s3
                schema: v11
                index:
                  prefix: loki_index_
                  period: 24h
                  
            server:
              http_listen_port: 3100
              grpc_listen_port: 9095
              
            storage_config:
              boltdb_shipper:
                active_index_directory: /loki/boltdb-shipper-active
                cache_location: /loki/boltdb-shipper-cache
                cache_ttl: 24h
                shared_store: s3
              aws:
                s3: s3://@storage.yandexcloud.net/tfstate-k8s-airflow-2025-07-09
                s3forcepathstyle: true
                bucketnames: tfstate-k8s-airflow-2025-07-09
                endpoint: storage.yandexcloud.net
                region: ru-central1
                
            chunk_store_config:
              max_look_back_period: 0s
              
            table_manager:
              retention_deletes_enabled: false
              retention_period: 0s
              
            compactor:
              working_directory: /loki/boltdb-shipper-compactor
              shared_store: s3
              
          # Volumes для временных файлов
          extraVolumes:
            - name: tmp
              emptyDir: {}
            - name: cache
              emptyDir:
                sizeLimit: 10Gi
                
          extraVolumeMounts:
            - name: tmp
              mountPath: /tmp
            - name: cache
              mountPath: /loki
              
          # Environment variables для S3 credentials
          extraEnv:
            - name: AWS_ACCESS_KEY_ID
              valueFrom:
                secretKeyRef:
                  name: loki-s3-credentials
                  key: access-key
            - name: AWS_SECRET_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: loki-s3-credentials
                  key: secret-key
                  
          # Service Monitor for Prometheus
          serviceMonitor:
            enabled: true
            namespace: monitoring
            labels:
              prometheus: kube-prometheus
              
          # Network Policy
          networkPolicy:
            enabled: false
            
        # Promtail configuration
        promtail:
          enabled: true
          
          # Resources
          resources:
            requests:
              cpu: 50m
              memory: 64Mi
            limits:
              cpu: 200m
              memory: 256Mi
              
          # RBAC
          rbac:
            create: true
            pspEnabled: false
            
          # ServiceAccount
          serviceAccount:
            create: true
            
          # Config
          config:
            serverPort: 3101
            clients:
              - url: http://loki-stack:3100/loki/api/v1/push
                
            snippets:
              # Common config
              pipelineStages:
              - docker: {}
              
              # Airflow specific parsing
              - match:
                  selector: '{namespace="airflow"}'
                  stages:
                  - regex:
                      expression: '.*\[(?P<timestamp>.*?)\].*\{(?P<dag_id>.*?)\}.*\[(?P<task_id>.*?)\].*'
                  - labels:
                      dag_id:
                      task_id:
                  - timestamp:
                      format: '2006-01-02 15:04:05,000'
                      source: timestamp
                      
              # Labels from filename
              - regex:
                  expression: '.*\/(?P<namespace>.*?)_(?P<pod>.*?)_(?P<container>.*?)\/.*'
                  
              - labels:
                  namespace:
                  pod:
                  container:
                      
              # Drop debug logs
              - match:
                  selector: '{level="debug"}'
                  action: drop
                  
          # DaemonSet options
          tolerations:
          - key: node-role.kubernetes.io/master
            operator: Exists
            effect: NoSchedule
          - key: node-role.kubernetes.io/control-plane
            operator: Exists
            effect: NoSchedule
            
          # Volume for journal logs
          extraVolumes:
          - name: journal
            hostPath:
              path: /var/log/journal
              
          extraVolumeMounts:
          - name: journal
            mountPath: /var/log/journal
            readOnly: true
            
          # Service Monitor
          serviceMonitor:
            enabled: true
            namespace: monitoring
            labels:
              prometheus: kube-prometheus
              
        # Fluent-bit (альтернатива promtail, отключено)
        fluent-bit:
          enabled: false
          
        # Grafana (используем из prometheus-stack)
        grafana:
          enabled: false
          
        # Prometheus (используем из prometheus-stack)
        prometheus:
          enabled: false

  destination:
    server: https://kubernetes.default.svc
    namespace: monitoring

  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
    - CreateNamespace=true
    - Replace=true
    retry:
      limit: 5
      backoff:
        duration: 5s
        factor: 2
        maxDuration: 3m

  revisionHistoryLimit: 10